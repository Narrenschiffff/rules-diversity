{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72e04ddd",
   "metadata": {},
   "source": [
    "# Cell 0 — 环境与路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3533ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os, sys, shlex, glob, re, subprocess\n",
    "import shlex, threading, queue\n",
    "from pathlib import Path\n",
    "from typing import Iterable, List, Union\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --------------- 目录与 CLI ---------------\n",
    "NB_DIR = Path.cwd()\n",
    "ROOT = NB_DIR.parent if (NB_DIR.name.lower() == \"notebooks\") else NB_DIR\n",
    "PY = sys.executable\n",
    "CLI = ROOT / \"scripts\" / \"rd_cli.py\"\n",
    "assert CLI.exists(), f\"rd_cli.py not found at {CLI}\"\n",
    "\n",
    "RES_ROOT = ROOT / \"notebooks\" / \"results\"\n",
    "OUT_CSV  = RES_ROOT / \"out_csv\"\n",
    "OUT_FIG  = RES_ROOT / \"figs\"\n",
    "OUT_SYM  = RES_ROOT / \"symmetry\"\n",
    "for d in [OUT_CSV, OUT_FIG, OUT_SYM]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "STYLE  = \"ieee\"\n",
    "DEVICE = \"cuda\" if (shutil.which(\"nvidia-smi\") is not None) else \"cpu\"\n",
    "\n",
    "\n",
    "\n",
    "def _pump_stream(stream, label, outq):\n",
    "    for line in iter(stream.readline, ''):\n",
    "        outq.put((label, line.rstrip('\\n')))\n",
    "    stream.close()\n",
    "\n",
    "def safe_run(cmd, cwd=None, check=False, env=None):\n",
    "    \"\"\"\n",
    "    实时把子进程 stdout / stderr 逐行打印到 Notebook。\n",
    "    返回 (retcode, cmd_str)。\n",
    "    \"\"\"\n",
    "    cmd = [str(c) for c in cmd]\n",
    "    # 若是 python，强制无缓冲\n",
    "    if len(cmd) >= 1 and os.path.basename(cmd[0]).lower().startswith(\"python\"):\n",
    "        if \"-u\" not in cmd[1:2]:\n",
    "            cmd = [cmd[0], \"-u\"] + cmd[1:]\n",
    "    cmd_str = \" \".join(shlex.quote(x) for x in cmd)\n",
    "    print(\"[run]\", cmd_str, flush=True)\n",
    "\n",
    "    env2 = os.environ.copy()\n",
    "    env2[\"PYTHONUNBUFFERED\"] = \"1\"\n",
    "    if env:\n",
    "        env2.update(env)\n",
    "\n",
    "    proc = subprocess.Popen(\n",
    "        cmd, cwd=str(cwd) if cwd else None,\n",
    "        stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n",
    "        universal_newlines=True, bufsize=1, env=env2\n",
    "    )\n",
    "    outq = queue.Queue()\n",
    "\n",
    "    t1 = threading.Thread(target=_pump_stream, args=(proc.stdout, \"STDOUT\", outq), daemon=True)\n",
    "    t2 = threading.Thread(target=_pump_stream, args=(proc.stderr, \"STDERR\", outq), daemon=True)\n",
    "    t1.start(); t2.start()\n",
    "\n",
    "    # 主循环：交替转发两路输出\n",
    "    while True:\n",
    "        try:\n",
    "            label, line = outq.get(timeout=0.05)\n",
    "            if label == \"STDERR\":\n",
    "                print(\"┈\", line, flush=True)\n",
    "            else:\n",
    "                print(line, flush=True)\n",
    "        except queue.Empty:\n",
    "            if proc.poll() is not None:\n",
    "                break\n",
    "\n",
    "    t1.join(timeout=0.1); t2.join(timeout=0.1)\n",
    "    ret = proc.returncode\n",
    "    if check and ret != 0:\n",
    "        raise RuntimeError(f\"Command failed (ret={ret}): {cmd_str}\")\n",
    "    return ret, cmd_str\n",
    "\n",
    "\n",
    "def build_cmd(base_subcmd:str, base:list[str], opts:dict)->list[str]:\n",
    "    \"\"\"\n",
    "    智能构造命令：仅添加 bool True 的 flag；None/False 不加；其余转为字符串。\n",
    "    \"\"\"\n",
    "    cmd = base[:]\n",
    "    for k, v in opts.items():\n",
    "        if isinstance(v, bool):\n",
    "            if v: cmd.append(k)\n",
    "        elif v is not None:\n",
    "            cmd += [k, str(v)]\n",
    "    return cmd\n",
    "\n",
    "def glob_many(*patterns: Union[str, Path], dedup: bool = True) -> List[str]:\n",
    "    \"\"\"\n",
    "    支持 Path / str 混合，返回绝对路径字符串列表。\n",
    "    - dedup=True: 去重并按路径排序\n",
    "    \"\"\"\n",
    "    files: List[str] = []\n",
    "    for pat in patterns:\n",
    "        pat_str = str(pat)\n",
    "        files.extend(glob.glob(pat_str))\n",
    "    if dedup:\n",
    "        files = sorted(set(files))\n",
    "    else:\n",
    "        files = sorted(files)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6b437a",
   "metadata": {},
   "source": [
    "# Cell 1 — CLI 子命令帮助（可快速确认参数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c23de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in [\"stage1\",\"ga\",\"viz-all\",\"entropy\",\"archetypes\",\"symmetry\",\"motifs\",\"motifs-explain\"]:\n",
    "    cmd = [PY, str(CLI), sub, \"-h\"]\n",
    "    _ = subprocess.run(cmd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf04d1e",
   "metadata": {},
   "source": [
    "# Cell 2 — 批量运行 stage1（小规模穷举）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d23b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage1_exists(n:int, k:int)->bool:\n",
    "    pats = [OUT_CSV / f\"stage1_pareto_n{n}_k{k}_*.csv\"]\n",
    "    return any(glob.glob(str(p)) for p in pats)\n",
    "\n",
    "def list_stage1_outputs(n:int, k:int):\n",
    "    pats = [OUT_CSV / f\"stage1_all_n{n}_k{k}_*.csv\",\n",
    "            OUT_CSV / f\"stage1_pareto_n{n}_k{k}_*.csv\"]\n",
    "    files = []\n",
    "    for p in pats: files += glob.glob(str(p))\n",
    "    return sorted(files)\n",
    "\n",
    "def run_stage1(n:int, k:int, reuse=True):\n",
    "    if reuse and stage1_exists(n, k):\n",
    "        print(f\"[stage1] reuse n={n},k={k}\")\n",
    "        return 0\n",
    "    cmd = [PY, str(CLI), \"stage1\", \"--n\", str(n), \"--k\", str(k),\n",
    "           \"--out-csv\", str(OUT_CSV), \"--style\", STYLE]\n",
    "    ret = safe_run(cmd, cwd=ROOT)\n",
    "    outs = list_stage1_outputs(n, k)\n",
    "    print(f\"[stage1] outputs ({n},{k}) ->\", len(outs)); [print(\"  •\",x) for x in outs]\n",
    "    return ret\n",
    "\n",
    "ret_log = []\n",
    "for n in range(2, 5):       # n = 2,3,4\n",
    "    for k in range(2, n+1): # k <= n\n",
    "        rc = run_stage1(n, k, reuse=False)  # 首次建议设 reuse=False 强制重跑\n",
    "        ret_log.append((n, k, rc))\n",
    "ret_log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c7d0da",
   "metadata": {},
   "source": [
    "# Cell 3 — 批量运行 GA（可复用已有前沿）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7864582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ga_front_exists(n:int, k:int)->bool:\n",
    "    pats = [OUT_CSV / f\"pareto_front_n{n}_k{k}*.csv\"]\n",
    "    return any(glob.glob(str(p)) for p in pats)\n",
    "\n",
    "def list_ga_outputs(n:int, k:int):\n",
    "    pats = [OUT_CSV / f\"pareto_front_n{n}_k{k}*.csv\",\n",
    "            OUT_CSV / f\"gen_summary_n{n}_k{k}*.csv\"]\n",
    "    files = []\n",
    "    for p in pats: files += glob.glob(str(p))\n",
    "    return sorted(files)\n",
    "\n",
    "def run_ga(n:int, k:int, device=DEVICE, reuse=True,\n",
    "           pop=24, gens=10, p_mut=0.08, p_cx=0.85, elite_keep=6,\n",
    "           r_vals=3, power_iters=60, trace_mode=\"hutchpp\", hutch_s=24,\n",
    "           seed_from_stage1=True, max_stage1_seeds=400,\n",
    "           fast_eval=False, progress_every=8):\n",
    "    if reuse and ga_front_exists(n,k):\n",
    "        print(f\"[GA] reuse n={n},k={k}\"); return 0\n",
    "    base = [PY, str(CLI), \"ga\", \"--n\", str(n), \"--k\", str(k)]\n",
    "    opts = {\n",
    "        \"--out-csv\": str(OUT_CSV), \"--device\": device,\n",
    "        \"--pop-size\": pop, \"--generations\": gens,\n",
    "        \"--p-mut\": p_mut, \"--p-cx\": p_cx, \"--elite-keep\": elite_keep,\n",
    "        \"--r-vals\": r_vals, \"--power-iters\": power_iters,\n",
    "        \"--trace-mode\": trace_mode, \"--hutch-s\": hutch_s,\n",
    "        \"--seed-from-stage1\": bool(seed_from_stage1),\n",
    "        \"--max-stage1-seeds\": max_stage1_seeds,\n",
    "        \"--fast-eval\": bool(fast_eval),\n",
    "        \"--progress-every\": progress_every\n",
    "    }\n",
    "    cmd = build_cmd(\"ga\", base, opts)\n",
    "    ret = safe_run(cmd, cwd=ROOT)\n",
    "    outs = list_ga_outputs(n,k)\n",
    "    print(f\"[GA] outputs ({n},{k}) ->\", len(outs)); [print(\"  •\",x) for x in outs]\n",
    "    return ret\n",
    "\n",
    "ret_ga = []\n",
    "for n in range(2, 7):  \n",
    "    for k in range(2, n+1):\n",
    "        rc = run_ga(n, k, seed_from_stage1=True, fast_eval=False, reuse=False) \n",
    "        ret_ga.append((n, k, rc))\n",
    "ret_ga[:10], \" ... \", len(ret_ga)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b402843",
   "metadata": {},
   "source": [
    "# Cell 4 — 汇聚表（master_index）与 front_paths 构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0469d980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csvs(patterns):\n",
    "    files = []\n",
    "    for pat in patterns:\n",
    "        files.extend(glob.glob(str(OUT_CSV / pat)))\n",
    "    dfs = []\n",
    "    for f in sorted(set(files)):\n",
    "        try:\n",
    "            df = pd.read_csv(f)\n",
    "            df[\"__file__\"] = Path(f).name\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(\"[WARN] skip\", f, \"->\", e)\n",
    "    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
    "\n",
    "# 读取 stage1 的全量与前沿、GA 的前沿\n",
    "df_stage1_all    = read_csvs([\"stage1_all_*.csv\"])\n",
    "df_stage1_pareto = read_csvs([\"stage1_pareto_*.csv\"])\n",
    "df_ga_front      = read_csvs([\"pareto_front_*.csv\"])\n",
    "\n",
    "def normalize_cols(df):\n",
    "    if df is None or df.empty: \n",
    "        return df\n",
    "    # 统一“二目标”的值列名称到 trace_or_Z（便于下游汇聚）\n",
    "    if \"Z_exact\" in df.columns:\n",
    "        df = df.rename(columns={\"Z_exact\": \"trace_or_Z\"})\n",
    "    if \"sum_lambda_powers\" in df.columns:\n",
    "        df = df.rename(columns={\"sum_lambda_powers\": \"trace_or_Z\"})\n",
    "    return df\n",
    "\n",
    "df_s1a = normalize_cols(df_stage1_all).assign(source=\"stage1_all\") if not df_stage1_all.empty else pd.DataFrame()\n",
    "df_s1p = normalize_cols(df_stage1_pareto).assign(source=\"stage1_pareto\") if not df_stage1_pareto.empty else pd.DataFrame()\n",
    "df_gaf = normalize_cols(df_ga_front).assign(source=\"ga_front\") if not df_ga_front.empty else pd.DataFrame()\n",
    "\n",
    "_non_empty = [x for x in [df_s1a, df_s1p, df_gaf] if (x is not None and not x.empty)]\n",
    "if _non_empty:\n",
    "    master = pd.concat(_non_empty, ignore_index=True)\n",
    "    print(\"[master] shape:\", master.shape, \"columns:\", master.columns.tolist())\n",
    "    master_path = OUT_CSV / \"master_index.csv\"\n",
    "    master.to_csv(master_path, index=False)\n",
    "else:\n",
    "    print(\"[master] no inputs -> empty master; skip writing master_index.csv\")\n",
    "    master = pd.DataFrame()\n",
    "    master_path = OUT_CSV / \"master_index.csv\"\n",
    "\n",
    "# ---- 构建 front_paths（供 Cell 5/6/8 使用）----\n",
    "front_paths = glob_many(OUT_CSV/\"stage1_pareto_*.csv\", OUT_CSV/\"pareto_front_*.csv\")\n",
    "print(\"front_paths =\", len(front_paths))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a96860",
   "metadata": {},
   "source": [
    "# Cell 5 — 批次可视化：viz-all（三图）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35713a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 批量可视化：每张图一个 (n,k)，同图对比 raw & canon =====\n",
    "import os, re, glob\n",
    "from pathlib import Path\n",
    "\n",
    "MAX_COMBOS_PER_FIG = 1  # 一图一个 (n,k)\n",
    "\n",
    "rx_stage1 = re.compile(r\"stage1_(?:all|pareto)_n(\\d+)_k(\\d+)\")\n",
    "rx_ga     = re.compile(r\"pareto_front_(?:nk_)?n(\\d+)_k(\\d+)(?:_|\\.csv)\")\n",
    "\n",
    "pair2files = {}\n",
    "for p in front_paths:\n",
    "    fname = os.path.basename(p)\n",
    "    m = rx_stage1.search(fname) or rx_ga.search(fname)\n",
    "    if not m:\n",
    "        continue\n",
    "    n, k = int(m.group(1)), int(m.group(2))\n",
    "    pair2files.setdefault((n, k), []).append(p)\n",
    "\n",
    "pairs_sorted = sorted(pair2files.keys(), key=lambda t: (t[0], t[1]))\n",
    "if not pairs_sorted:\n",
    "    print(\"[viz-all(nk)] No pareto CSVs to plot.\")\n",
    "else:\n",
    "    def chunks(lst, size):\n",
    "        for i in range(0, len(lst), size):\n",
    "            yield lst[i:i+size]\n",
    "\n",
    "    for batch_idx, batch_pairs in enumerate(chunks(pairs_sorted, MAX_COMBOS_PER_FIG), 1):\n",
    "        n0, k0 = batch_pairs[0]\n",
    "        batch_files = pair2files[(n0, k0)]\n",
    "        out_dir = OUT_FIG / f\"viz_n{n0}_k{k0}\"\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        cmd = [PY, str(CLI), \"viz-all\",\n",
    "               \"--front\", *batch_files,\n",
    "               \"--n\", str(n0), \"--k\", str(k0),\n",
    "               \"--out-dir\", str(out_dir),\n",
    "               \"--style\", STYLE,\n",
    "               \"--y-log\"]\n",
    "        ret, _ = safe_run(cmd, cwd=ROOT)\n",
    "        if ret != 0:\n",
    "            print(f\"[viz-all(nk) {n0},{k0}] ERROR: ret={ret}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ce70d9",
   "metadata": {},
   "source": [
    "# Cell 6 — 单图 viz-all（可选熵收敛叠加）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54e7066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 从 stage1 前沿选一条规则用于熵收敛绘图（可选）\n",
    "bits_candidate = None\n",
    "k_candidate = None\n",
    "if ('df_stage1_pareto' in globals()\n",
    "    and df_stage1_pareto is not None\n",
    "    and not df_stage1_pareto.empty\n",
    "    and \"rule_bits\" in df_stage1_pareto.columns):\n",
    "    row = df_stage1_pareto.loc[df_stage1_pareto[\"trace_or_Z\"].idxmax()] \\\n",
    "          if \"trace_or_Z\" in df_stage1_pareto.columns else \\\n",
    "          df_stage1_pareto.iloc[0]\n",
    "    bits_candidate = str(row[\"rule_bits\"])\n",
    "    k_candidate = int(row[\"k\"])\n",
    "    print(\"entropy rule candidate:\", bits_candidate[:32]+\"...\", \"k=\", k_candidate)\n",
    "\n",
    "if not front_paths:\n",
    "    print(\"[viz-all] skipped (no fronts).\")\n",
    "else:\n",
    "    cmd = [PY, str(CLI), \"viz-all\",\n",
    "           \"--out-dir\", str(OUT_FIG),\n",
    "           \"--style\", STYLE,\n",
    "           \"--y-log\",\n",
    "           \"--front\", *front_paths]\n",
    "\n",
    "    if bits_candidate is not None and k_candidate is not None:\n",
    "        cmd += [\"--entropy-bits\", bits_candidate,\n",
    "                \"--entropy-k\", str(k_candidate),\n",
    "                \"--n-min\", \"3\", \"--n-max\", \"6\",\n",
    "                \"--device\", DEVICE]\n",
    "\n",
    "    ret, _ = safe_run(cmd, cwd=ROOT)\n",
    "    print(\"[viz-all] return code:\", ret)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259b0727",
   "metadata": {},
   "source": [
    "# Cell 7 — motifs → motifs-explain 全流程（一键）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b15fbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Cell 7 — 一键“膝点 → 解释器”流水线（CLI）\n",
    "# 先生成 motifs（三段样本+summary+global），再运行 motifs-explain（Δ特征解释）\n",
    "# =========================\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "if not front_paths:\n",
    "    raise RuntimeError(\"未找到前沿 CSV，请先运行 stage1/ga 以生成 stage1_pareto_*.csv 或 pareto_front_*.csv。\")\n",
    "\n",
    "OUT_MOTIF_CSV = OUT_CSV / \"motifs\"\n",
    "OUT_MOTIF_FIG = OUT_FIG / \"motifs\"\n",
    "OUT_MOTIF_CSV.mkdir(parents=True, exist_ok=True)\n",
    "OUT_MOTIF_FIG.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) 运行 CLI：motifs（生成 examples/summary/global）\n",
    "cmd_motifs = [\n",
    "    PY, str(CLI), \"motifs\",\n",
    "    \"--front\", *front_paths,     # ← 已解析具体文件\n",
    "    \"--out-csv\", str(OUT_MOTIF_CSV),\n",
    "    \"--out-dir\", str(OUT_MOTIF_FIG),\n",
    "    \"--style\", STYLE,\n",
    "    \"--y-log\",\n",
    "]\n",
    "ret, _ = safe_run(cmd_motifs, cwd=ROOT)\n",
    "if ret != 0:\n",
    "    raise RuntimeError(f\"[Cell7] rd_cli.py motifs ret={ret}\")\n",
    "\n",
    "# 2) 解析索引并存在性检查\n",
    "index_file = OUT_MOTIF_CSV / \"motifs_index.txt\"\n",
    "if index_file.exists():\n",
    "    paths = {}\n",
    "    for line in index_file.read_text(encoding=\"utf-8\").splitlines():\n",
    "        if \"=\" in line:\n",
    "            k, v = line.split(\"=\", 1)\n",
    "            paths[k.strip()] = v.strip()\n",
    "    ex_csv   = Path(paths.get(\"examples\", OUT_MOTIF_CSV / \"motif_knee_examples.csv\"))\n",
    "    sum_csv  = Path(paths.get(\"summary\",  OUT_MOTIF_CSV / \"motif_knee_summary.csv\"))\n",
    "    glob_csv = Path(paths.get(\"global\",   OUT_MOTIF_CSV / \"motif_global_report.csv\"))\n",
    "else:\n",
    "    ex_csv   = OUT_MOTIF_CSV / \"motif_knee_examples.csv\"\n",
    "    sum_csv  = OUT_MOTIF_CSV / \"motif_knee_summary.csv\"\n",
    "    glob_csv = OUT_MOTIF_CSV / \"motif_global_report.csv\"\n",
    "\n",
    "for p in [ex_csv, sum_csv, glob_csv]:\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"[Cell7] 预期输出缺失：{p}\")\n",
    "print(\"[Cell7] examples_csv =\", ex_csv)\n",
    "print(\"[Cell7] summary_csv  =\", sum_csv)\n",
    "print(\"[Cell7] global_csv   =\", glob_csv)\n",
    "\n",
    "# 3) 运行 CLI：motifs-explain（不重复生成 viz 的 nk 增长曲线）\n",
    "cmd_explain = [\n",
    "    PY, str(CLI), \"motifs-explain\",\n",
    "    \"--examples\", str(ex_csv),\n",
    "    \"--out-csv\", str(OUT_MOTIF_CSV),\n",
    "    \"--out-dir\", str(OUT_MOTIF_FIG),\n",
    "    \"--style\", STYLE,\n",
    "    \"--topN\", \"20\",\n",
    "    \"--tree-depth\", \"3\",\n",
    "    \"--tree-min-leaf\", \"2\",\n",
    "    \"--seed\", \"0\",\n",
    "    # \"--include-growth\",   # 通常关闭；viz 已做\n",
    "]\n",
    "ret, _ = safe_run(cmd_explain, cwd=ROOT)\n",
    "if ret != 0:\n",
    "    raise RuntimeError(f\"[Cell7] rd_cli.py motifs-explain ret={ret}\")\n",
    "\n",
    "# 4) 产物总览与快速预览\n",
    "PRODUCTS = {\n",
    "    # 样本与概览\n",
    "    \"examples_csv\":  ex_csv,\n",
    "    \"summary_csv\":   sum_csv,\n",
    "    \"global_csv\":    glob_csv,\n",
    "    # 解释器 CSV\n",
    "    \"dataset_csv\":   OUT_MOTIF_CSV / \"motif_delta_dataset.csv\",\n",
    "    \"logreg_csv\":    OUT_MOTIF_CSV / \"motif_feature_importance_logreg.csv\",\n",
    "    \"tree_csv\":      OUT_MOTIF_CSV / \"motif_feature_importance_tree.csv\",\n",
    "    \"perm_csv\":      OUT_MOTIF_CSV / \"motif_perm_importance.csv\",\n",
    "    \"l1_coeffs\":     OUT_MOTIF_CSV / \"motif_lr_coeffs.csv\",\n",
    "    \"joint_table\":   OUT_MOTIF_CSV / \"spectrum_structure_joint.csv\",\n",
    "    \"integrity\":     OUT_MOTIF_CSV / \"integrity_report.json\",\n",
    "    # 图件\n",
    "    \"png_bar\":       OUT_MOTIF_FIG / \"knee_motif_bar.png\",\n",
    "    \"png_heatmap\":   OUT_MOTIF_FIG / \"knee_motif_heatmap.png\",\n",
    "    \"png_logreg\":    OUT_MOTIF_FIG / \"motif_importance_logreg.png\",\n",
    "    \"png_tree\":      OUT_MOTIF_FIG / \"motif_importance_tree.png\",\n",
    "    \"png_l1\":        OUT_MOTIF_FIG / \"motif_lr_coeffs.png\",\n",
    "    \"png_perm\":      OUT_MOTIF_FIG / \"motif_perm_importance.png\",\n",
    "}\n",
    "print(\"\\n[Cell7] 关键输出：\")\n",
    "for k, p in PRODUCTS.items():\n",
    "    print(f\"  - {k}: {p}\")\n",
    "\n",
    "# 5) 预览 joint 表（用于谱-结构-增长对照讲解）\n",
    "try:\n",
    "    joint = pd.read_csv(PRODUCTS[\"joint_table\"])\n",
    "    show_cols = [c for c in [\"n\",\"k\",\"rule_count\",\"y\",\"lambda1\",\"lambda2\",\"gap\",\"lap_algebraic\",\n",
    "                             \"deg_max\",\"diag_cnt\",\"kcore\",\"clustering\",\"tri\",\"c4\",\"c5\",\"near_bip_chord\",\n",
    "                             \"selfloop_rich\",\"star_core\"] if c in joint.columns]\n",
    "    if show_cols:\n",
    "        try:\n",
    "            display(joint[show_cols].head(10))\n",
    "        except Exception:\n",
    "            print(joint[show_cols].head(10).to_string(index=False))\n",
    "except Exception as e:\n",
    "    print(\"[Cell7] 联合表预览失败：\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d69a866",
   "metadata": {},
   "source": [
    "# Cell 8 — 前沿对称性统计与示例渲染（可选）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a326e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Cell 8 — 只用 CLI，聚焦膝点，尽量复用 =======\n",
    "import os, re, glob\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------- 可配置区 --------------\n",
    "TARGET_NK = (4 , 4)           # 固定目标 (n,k)；如不设则自动从 front_paths 解析第一个\n",
    "GEO_OPS = \"rot,ref,trans\"  # 几何对称集合\n",
    "STATE_PERM = True          # 是否启用状态置换对称\n",
    "SAMPLES = 512                # 采样条数（枚举不可行时）\n",
    "ENUM_LIMIT = 1_000_000     # 精确枚举上限，超过退化采样\n",
    "REUSE = False               # 若已有 symmetry_summary_n{k}_k{k}.csv 则直接复用\n",
    "KNEE_ONLY = True           # 仅对膝点代表规则做统计；如果 motifs 缺失或无匹配，则回退为全前沿\n",
    "\n",
    "# -------------- 解析 (n,k) --------------\n",
    "def _parse_nk_from_filename(p: str):\n",
    "    rx_stage1 = re.compile(r\"stage1_pareto_n(\\d+)_k(\\d+)\")\n",
    "    rx_ga     = re.compile(r\"pareto_front_(?:nk_)?n(\\d+)_k(\\d+)(?:_|\\.csv)\")\n",
    "    fn = os.path.basename(p)\n",
    "    m = rx_stage1.search(fn) or rx_ga.search(fn)\n",
    "    if m: return int(m.group(1)), int(m.group(2))\n",
    "    return None\n",
    "\n",
    "def _pick_target_nk(front_paths, target_nk=None):\n",
    "    if target_nk is not None:\n",
    "        return target_nk\n",
    "    # 否则挑第一个能解析的\n",
    "    for p in front_paths:\n",
    "        nk = _parse_nk_from_filename(p)\n",
    "        if nk: return nk\n",
    "    return None\n",
    "\n",
    "# -------------- 主流程 --------------\n",
    "if not front_paths:\n",
    "    raise RuntimeError(\"[Cell 8] 未发现 front_paths；请先完成 stage1/ga 以生成前沿 CSV。\")\n",
    "\n",
    "nk = _pick_target_nk(front_paths, TARGET_NK)\n",
    "if nk is None:\n",
    "    print(\"[Cell 8] 无法从 front_paths 解析 (n,k)，已跳过对称性分析。\")\n",
    "else:\n",
    "    n0, k0 = nk\n",
    "    fps = [p for p in front_paths if (f\"_n{n0}_k{k0}\" in p) or p.endswith(f\"n{n0}_k{k0}_canon.csv\")]\n",
    "    if not fps:\n",
    "        print(f\"[Cell 8] 未找到 n={n0},k={k0} 的前沿 CSV，已跳过。\")\n",
    "    else:\n",
    "        # 读取 motifs index → examples.csv，用于 --knee-only\n",
    "        motifs_idx = OUT_CSV / \"motifs\" / \"motifs_index.txt\"\n",
    "        examples_csv = None\n",
    "        if motifs_idx.exists():\n",
    "            kv = dict(line.strip().split(\"=\",1) for line in motifs_idx.read_text(encoding=\"utf-8\").splitlines() if \"=\" in line)\n",
    "            if \"examples\" in kv:\n",
    "                examples_csv = kv[\"examples\"]\n",
    "        # 若没 index，就尝试默认路径\n",
    "        if not examples_csv:\n",
    "            default_ex = OUT_CSV / \"motifs\" / \"motif_knee_examples.csv\"\n",
    "            if default_ex.exists(): examples_csv = str(default_ex)\n",
    "\n",
    "        cmd = [\n",
    "            PY, str(CLI), \"symmetry\",\n",
    "            \"--front\", *fps,\n",
    "            \"--n\", str(n0), \"--k\", str(k0),\n",
    "            \"--geo\", GEO_OPS,\n",
    "            \"--samples\", str(SAMPLES),\n",
    "            \"--enum-limit\", str(ENUM_LIMIT),\n",
    "            \"--out-csv\", str(OUT_SYM),\n",
    "            \"--out-dir\", str(OUT_FIG),\n",
    "            \"--style\", STYLE\n",
    "        ]\n",
    "        if STATE_PERM: cmd.append(\"--state-perm\")\n",
    "        if REUSE: cmd.append(\"--reuse\")\n",
    "        if KNEE_ONLY: cmd.append(\"--knee-only\")\n",
    "        if examples_csv: cmd += [\"--motifs-examples\", str(examples_csv)]\n",
    "\n",
    "        ret, _ = safe_run(cmd, cwd=ROOT)\n",
    "        if ret != 0:\n",
    "            print(f\"[Cell 8] symmetry CLI 失败（ret={ret}）\")\n",
    "        else:\n",
    "            # 汇报产物\n",
    "            summary_csv = OUT_SYM / f\"symmetry_summary_n{n0}_k{k0}.csv\"\n",
    "            print(\"[Cell 8] symmetry summary:\", summary_csv if summary_csv.exists() else \"(未生成)\")\n",
    "            figs = sorted(glob.glob(str(OUT_FIG / f\"*n{n0}_k{k0}*symmetry*.png\"))) or \\\n",
    "                   sorted(glob.glob(str(OUT_FIG / \"symmetry_*.png\")))\n",
    "            if figs:\n",
    "                print(\"[Cell 8] 示例图：\")\n",
    "                for p in figs: print(\"  •\", p)\n",
    "            else:\n",
    "                print(\"[Cell 8] 未发现示例图（模块命名可能不同，属正常）。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmcompressor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
